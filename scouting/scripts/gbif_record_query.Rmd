---
title: "gather and clean records from GBIF"
author: "steppe"
date: "2023-04-05"
output: pdf_document
---

Here we are going to query all of our target species to download occurrence records 
from biodiversity aggregation websites. 

```{r load libraries}
library(tidyverse)
library(sf)
library(rgbif)
library(BIEN)
library(nngeo)
source('functions.R')
```


```{r import species of interest}
p <- '../data'
f <- list.files(p)

target_taxa <- read.csv(file.path(p, f[grep('taxa', f)])) %>% 
  pull(Species)

```


```{r make gbif query, eval = F}
user <- "steppe" # your gbif.org username 
pwd <- "blmquery" # your gbif.org password # this one is now old and serves as an example
email <- "reedbenkendorf27@gmail.com" # your email 

gbif_taxon_keys <- target_taxa %>% 
  name_backbone_checklist()  %>% 
  filter(!matchType == "NONE") %>% 
  pull(usageKey)

gbif_taxon_keys
dl_key <- occ_download(
  pred_in("taxonKey", gbif_taxon_keys),
  user=user, pwd=pwd, email=email,
  pred("country", "US"),
  pred("hasCoordinate", TRUE),
  pred("hasGeospatialIssue", FALSE),
  pred_gte("year", 1900)
)

occ_download_wait('0145828-230224095556074')

d <- occ_download_get( dl_key ) %>%
    occ_download_import()

# these data were then downloaded via the GUI to a folder on lightscape and
# copied over onto the drive. 
# The column fields do not match very well, and you may need to load it in a
# spreadsheet manager such as the open source (free) libre calc

rm(user, pwd, email, d, gbif_taxon_keys, dl_key)
```

gbif citation: GBIF.org (05 April 2023) GBIF Occurrence Download https://doi.org/10.15468/dl.5cwpam

```{r import analytical area for modelling}

p <- '../../geodata'
f <- list.files(p, recursive = T, pattern = 'shp$')

field_off <- st_read(file.path(p, f[grep('GRT', f)]), quiet = T) %>% 
  st_union() %>% 
  st_as_sf() %>% 
  st_transform(5070)

field_off <- nngeo::st_remove_holes(field_off)
field_off <- st_buffer(field_off, dist = 50000)
field_off <- st_convex_hull(field_off)

```


```{r clean gbif records to the extent of study area, eval = F}

spp_occ <- read.delim(
  file.path(p, 
            list.files(p, recursive = T, pattern = 'occurrence.txt')),
  sep="\t",  header=TRUE, stringsAsFactors=FALSE, quote=""
  )[, c('gbifID', 'publisher', 'basisOfRecord', 'recordedBy', 
        'recordNumber', 'occurrenceStatus', 'month', 
        'day', 'year', 'continent', 'decimalLatitude', 'decimalLongitude', 
        'coordinateUncertaintyInMeters', 'taxonID', 'acceptedNameUsageID',
        'acceptedScientificName', 'order', 'family', 'genus', 'species', 'specificEpithet',
        'infraspecificEpithet', 'acceptedTaxonKey', 'taxonRank', 'verbatimScientificName'
        )] %>% 
  filter(occurrenceStatus == 'PRESENT', year >= 1900, 
         coordinateUncertaintyInMeters < 250, continent != 'OCEANIA') %>% 
  mutate(across(where(is.character), ~ na_if(.x, ''))) %>% 
  drop_na(specificEpithet) %>% 
  distinct(decimalLongitude, decimalLatitude, species, .keep_all = TRUE) %>% 
  st_as_sf(coords = c('decimalLongitude', 'decimalLatitude'), crs = 4326)

spp_occ <- spp_occ[
  st_covered_by(spp_occ, st_transform(field_off, st_crs(spp_occ))) %>% 
    lengths > 0,]

lkp_tab <- read.csv('../data/gbif_synonym_lkp.csv') %>% 
  rename(species_old = gbif, species = local_use)

syn <- spp_occ %>% 
  filter(!species %in% target_taxa) %>% 
  left_join(., lkp_tab, by = c('species' = 'species_old') ) %>% 
  select(-species, species = species.y) %>% 
  separate(species, into = c('genus', 'SpecificEpithet'), sep = " ", remove = F)

spp_occ <- bind_rows(spp_occ %>% 
  filter(species %in% target_taxa), syn) %>% 
  select(-gbifID, -publisher, -basisOfRecord)

ifelse(!dir.exists(file.path('../data', 'GBIF')), 
       dir.create(file.path('../data', 'GBIF')), FALSE)
st_write(spp_occ, file.path('../data', 'GBIF', 'GBIF_cleaned.shp'), append = F)

rm(syn, lkp_tab, spp_occ)
```

```{r download and clean bien records for study area, eval = F}

bien_dl <- lapply(target_taxa, BIEN_occurrence_species,
                  new.world = T, observation.type = T,  collection.info = T, 
                  only.geovalid = T)

bien_stuff <- bien_dl[sapply(bien_dl, function(x) dim(x)[1]) > 0] %>% 
  bind_rows() %>% 
  select(scrubbed_species_binomial:custodial_institution_codes, -dataset) %>% 
  st_as_sf(coords = c('longitude', 'latitude'), crs = 4326) %>% 
  rename(date = 'date_collected...4') %>% 
  drop_na(date)

bien_stuff <- bien_stuff[
  st_covered_by(bien_stuff, st_transform(field_off, st_crs(bien_stuff))) %>% 
    lengths > 0,]

bien_stuff <- bien_stuff %>% 
  mutate(year = str_extract(date, '^[0-9]{4}'), .after = date) %>% 
  filter(year >= 1900)

ifelse(!dir.exists(file.path('../data', 'BIEN')), 
       dir.create(file.path('../data', 'BIEN')), FALSE)
st_write(bien_stuff, file.path('../data', 'BIEN', 'BIEN_cleaned.shp'), append = F)

rm(bien_dl, bien_stuff)
```


```{r identify distinct records between gbif and bien, eval = F}

bien <- st_read(file.path('../data', 'BIEN', 'BIEN_cleaned.shp'), quiet = T)
gbif <- st_read(file.path('../data', 'GBIF', 'GBIF_cleaned.shp'), quiet = T)

bien <- bien %>% 
  st_transform(26911) %>% 
  arrange(scrbb__) 
bien_recs <- bien %>% 
  group_by(scrbb__) %>% 
  group_split()
names(bien_recs) <- unique(bien$scrbb__)

gbif_sub <- gbif %>% 
  st_transform(26911) %>% 
  arrange(species)  %>% 
  filter(species != 'Astragalus eremiticus')
gbif_recs <- gbif_sub %>% 
  group_by(species) %>% 
  group_split()
names(gbif_recs) <- unique(gbif_sub$species)

gbif_out <- mapply(dupe_dropper, x = gbif_recs, y = bien_recs, dist_thresh = 1000, 
               SIMPLIFY = FALSE) %>% 
  bind_rows()

gbif <- bind_rows(gbif_out, filter(gbif, species == 'Astragalus eremiticus')) %>% 
  unite('date', c('year', 'month', 'day'), sep = '-', remove = F ) %>% 
  mutate(date = as.Date(date)) %>% 
  select(species, date, year) 

consensus <- bien %>% 
  select(species = scrbb__, date, year) %>% 
  mutate(year = as.numeric(year)) %>% 
  bind_rows(gbif, .) %>% 
  arrange(species, year)

ifelse(!dir.exists(file.path('../data', 'BIEN-GBIF')), 
       dir.create(file.path('../data', 'BIEN-GBIF')), FALSE)
st_write(consensus, file.path('../data', 'BIEN-GBIF', 'BIEN-GBIF_cleaned.shp'), append = F)

rm(gbif_recs, bien, gbif, gbif_sub, bien_recs, gbif_out)
```


```{r include species occurrence records from BLM scouting work to dataset}

p <- '../data'
f <- list.files(p, recursive = T)

target_taxa_lkp <- read.csv(file.path(p, f[grep('taxa', f)])) %>% 
  select(species = Species, USDA.Code)

hist_scout <- st_read(
  file.path('../data', list.files(
    '../data', recursive = T, pattern = 'Scouting.*shp')), quiet = T) %>% 
  select(USDA.Code = ABBREV_NAM) %>% 
  right_join(., target_taxa_lkp, by = 'USDA.Code') %>% 
  select(species)%>% 
  filter(!st_is_empty(.)) %>% 
  st_transform(26911)

hist_coll <- read.csv(
  file.path('../../Historic_SOS_Collections/Historic_SOS_Collections_GreatBasin_0.csv')) %>% 
  select(species = NAME, x, y) %>% 
  st_as_sf(coords = c('x', 'y'), crs = 4269) %>% 
  filter(species %in% target_taxa) %>% 
  filter(!st_is_empty(.)) %>% 
  st_transform(26911)

hist_scout <- hist_scout %>% 
  arrange(species) 
scout_recs <- hist_scout %>% 
  group_by(species) %>% 
  group_split()
names(scout_recs) <- unique(hist_scout$species)

hist_coll <- hist_coll %>% 
  arrange(species)
coll_recs <- hist_coll %>% 
  group_by(species) %>% 
  group_split()
names(coll_recs) <- unique(hist_coll$species)

coll_recs_sub <- coll_recs[names(coll_recs) %in% names(scout_recs)]
scout_recs_sub <- scout_recs[names(scout_recs) %in% names(coll_recs)]

only_one_set <- c(names(coll_recs)[!names(coll_recs) %in% names(scout_recs)],
                  names(scout_recs)[!names(scout_recs) %in% names(coll_recs)] )

coll_recs_out <- mapply(dupe_dropper, x = coll_recs_sub, y = scout_recs_sub, dist_thresh = 1000, 
               SIMPLIFY = FALSE) %>% 
  bind_rows()

single_set_species <- bind_rows(
    hist_coll %>% 
      filter(species %in% only_one_set),
    hist_scout %>% 
      filter(species %in% only_one_set)
)

hist_data <- bind_rows(coll_recs_out, hist_scout, single_set_species) %>% 
  arrange(species) 

rm(target_taxa_lkp, hist_coll, hist_scout, scout_recs_sub, coll_recs_sub, 
   scout_recs, coll_recs, coll_recs_out, single_set_species, only_one_set)
```


```{r combine all data for training sets}

gbif_bien <- st_read(file.path('../data', 'BIEN-GBIF', 'BIEN-GBIF_cleaned.shp'))

gb_recs <- gbif_bien %>% 
  group_by(species) %>% 
  group_split()
names(gb_recs) <- unique(gbif_bien$species)

hist_coll <- hist_data %>% 
  arrange(species)
coll_recs <- hist_coll %>% 
  group_by(species) %>% 
  group_split()
names(coll_recs) <- unique(hist_data$species)

gb_recs_sub <- gb_recs[names(gb_recs) %in% names(coll_recs)]
coll_recs_sub <- coll_recs[names(coll_recs) %in% names(gb_recs)]

only_one_set <- c(names(coll_recs)[!names(gb_recs) %in% names(coll_recs)],
                  names(gb_recs)[!names(coll_recs) %in% names(gb_recs)] )

coll_out <- mapply(dupe_dropper, x = coll_recs_sub, y = gb_recs_sub, dist_thresh = 1000, 
               SIMPLIFY = FALSE) %>% 
  bind_rows()

single_set_species <- bind_rows(
    hist_coll %>% 
      filter(species %in% only_one_set),
    gbif_bien %>% 
      filter(species %in% only_one_set)
)

hist_data <- bind_rows(coll_out, gbif_bien, single_set_species) %>% 
  arrange(species) %>% 
  relocate(date:year, .before = geometry)

ifelse(!dir.exists(file.path('../data', 'SDM-occ')), 
       dir.create(file.path('../data', 'SDM-occ')), FALSE)
st_write(hist_data, file.path('../data', 'SDM-occ', 'SDM-occ.shp'), append = F)

rm(single_set_species, only_one_set, coll_recs_out, coll_recs_sub, gb_recs_sub, 
   hist_coll, coll_recs, coll_out, conc_out, gb_recs, gbif_bien, hist_sub, hist_data)
```

```{r clean environment}
rm(hist_data, f, p, target_taxa, dupe_dropper)
```

