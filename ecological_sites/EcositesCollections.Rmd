---
title: "Generate List of Prospective Ecosites for Collections"
author: "steppe"
date: '2023-09-12'
output:
  pdf_document: default
  html_document: default
---

```{r, echo = F}
knitr::opts_chunk$set(
  echo = FALSE,  
  message = FALSE, 
  warning = FALSE 
)
```

```{r Load Libraries, echo = F, warning = F, message = F}
library(tidyverse)
library(sf)
library(terra)
library(FedData)
```

```{r import data for verifying ESDs of site locations}

d <- read.csv('Great_Basin_X_Utah_Seed_Collection_2023_0.csv') %>% 
  select(Object.ID = ObjectID, Latitude, Ref.NO = Seed.Collection.Reference.Number,
         Longitude, Slope = Approximate.Slope.in.Degrees, Aspect, Soil.Texture, Soil.Color = SOIL_COLOR, 
         Landform = Land.Form, Geology,
         Collectors = Collector.Name.s., Associated.Species = Associated.Species.List) %>% 
  drop_na('Longitude') %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = 4326) %>% 
  filter(!str_detect(Ref.NO, 'FWS0800')) %>% 
  mutate(
    Soil.Texture = na_if(Soil.Texture, 'Other'),
    Soil.Color = na_if(Soil.Color, 'Edit')
    )

```


```{r}

fname <- 'data/SOS_Collections.kml'
dplyr::select(d, Name = Ref.NO) |>
    sf::st_write(dsn = fname, driver = 'kml', quiet = T, append = F)
```

```{r export spatial query}
dspat <- d %>% 
  st_transform(5070) %>% 
  vect() %>% 
  buffer(width = 75, quadsegs = 1) 
xy <- crds(dspat)
dspat <- spin(dspat, 45, xy[,1], xy[,2])

dspat <- st_as_sf(dspat) %>% 
  st_transform(4269) %>% 
  select(Object.ID, Ref.NO)

states <- tigris::states() %>% 
  filter(STUSPS %in% c('NV', 'OR', 'UT'))

ggplot() +
  geom_sf(data = states) +
  geom_sf(data = d)

# dir.create('data/CollectionSites') # don't bother WSS still sucks
# st_write(dspat, 'data/CollectionSites/CollectionSites.shp')
# zip(zipfile = 'data/CollectionSites.zip', files = 'data/CollectionSites')

rm(xy, states)
```

```{r download ssurgo using feddata, eval = F}

dspat_p <- st_bbox(dspat) %>%  
  st_as_sfc() %>%  
  st_as_sf() 

get_ssurgo(template = dspat_p, label = 'GreatBasin', raw.dir = '../geodata/SSURGO/raw',
           extraction.dir = '../geodata/SSURGO/final')

```

```{r export copies}
VEG <- c('JUOS', 'ARNO4', 'PIMO', 'POSE', 'GUSA2', 'ARCAB3', 'PLJA', 'ACHY', 'ELEL5', 'HECO26', 
         'SAVE4', 'GUSA2', 'PSSP6', 'SABA14', 'ATRIP', 'SPORO', 'FEID', 'KOMA', 'ACTH7', 'LECI4' )
v <- paste(VEG, collapse = "|")



done <- read.csv('Great_Basin_X_Utah_Seed_Collection_2023_0.csv', na.strings = "") %>% 
  select(ObjectID, 
         ESD ='Ecological.Site.Description..Habitat.Type.and.or.National.Vegetation.Classification') %>% 
  mutate(Classified = if_else(str_detect(ESD, 'R0|F0'), T, F))

d %>% 
  left_join(., done, by = c('Object.ID' = 'ObjectID')) %>% 
  filter(Classified == F) %>% 
  mutate(Longitude = round(st_coordinates(.)[,1], 3), 
         Latitude = round(st_coordinates(.)[,2], 3),
         Veg = str_extract_all(Associated.Species, v, simplify = F),
         .before = Collectors) %>% 
  rowwise() %>% 
  mutate(across(starts_with('VEG'), toString)) %>% 
  st_drop_geometry() %>% 
  arrange(Ref.NO) %>% 
  write.csv(., 'data/SiteCharacteristics.csv', row.names = F)
  

colnames(d)
```

